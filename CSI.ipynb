{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_epochs = 50\n",
    "T = 24\n",
    "D = 122\n",
    "D1 = 100\n",
    "n_users = 226791\n",
    "vj_size = 20\n",
    "Wu_size = 100\n",
    "reg = 0.01\n",
    "p = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./labels.json') as json_data:\n",
    "    labels = json.load(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./labeltest.json') as json_data:\n",
    "    labels_test = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226791, 792)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.load('./mask.npy')\n",
    "mask.shape\n",
    "mask = mask.T\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226791, 199)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskTest = np.load('./mask_test.npy')\n",
    "maskTest = maskTest.T\n",
    "maskTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226791, 50)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = np.load('./finalscore_y.npy')\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 24, 122)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "X = np.zeros((792, 24, 122))\n",
    "i = 0\n",
    "label = []\n",
    "import os\n",
    "for e in os.listdir('./_FinalInputVectors/'):\n",
    "    label.append(e)\n",
    "    x = np.load('./_FinalInputVectors/'+e)\n",
    "    X[i] = x[:24]\n",
    "    i = i+1\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 24, 122)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "X_test = np.zeros((199, 24, 122))\n",
    "i = 0\n",
    "label_test = []\n",
    "import os\n",
    "for e in os.listdir('./FinalInputTestVectors/'):\n",
    "    label_test.append(e)\n",
    "    x = np.load('./FinalInputTestVectors/'+e)\n",
    "    X_test[i] = x[:24]\n",
    "    i = i+1\n",
    "print (X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 792, 122)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= X.swapaxes(0,1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 199, 122)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test= X_test.swapaxes(0,1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventId = []\n",
    "for l in label:\n",
    "    regex =re.compile(r'\\d+')\n",
    "    eventId.append(regex.findall(l))\n",
    "eventId = [item for sublist in eventId for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testeventId = []\n",
    "for l in label_test:\n",
    "    regex =re.compile(r'\\d+')\n",
    "    testeventId.append(regex.findall(l))\n",
    "testeventId = [item for sublist in testeventId for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['277',\n",
       " '870',\n",
       " '451',\n",
       " '645',\n",
       " '804',\n",
       " '116',\n",
       " '965',\n",
       " '249',\n",
       " '91',\n",
       " '382',\n",
       " '635',\n",
       " '543',\n",
       " '42',\n",
       " '583',\n",
       " '337',\n",
       " '274',\n",
       " '908',\n",
       " '431',\n",
       " '607',\n",
       " '158',\n",
       " '166',\n",
       " '937',\n",
       " '987',\n",
       " '743',\n",
       " '283',\n",
       " '961',\n",
       " '167',\n",
       " '782',\n",
       " '515',\n",
       " '125',\n",
       " '766',\n",
       " '425',\n",
       " '814',\n",
       " '237',\n",
       " '604',\n",
       " '403',\n",
       " '279',\n",
       " '364',\n",
       " '386',\n",
       " '673',\n",
       " '670',\n",
       " '514',\n",
       " '316',\n",
       " '401',\n",
       " '798',\n",
       " '224',\n",
       " '519',\n",
       " '655',\n",
       " '760',\n",
       " '983',\n",
       " '513',\n",
       " '920',\n",
       " '223',\n",
       " '39',\n",
       " '66',\n",
       " '254',\n",
       " '979',\n",
       " '982',\n",
       " '432',\n",
       " '688',\n",
       " '902',\n",
       " '319',\n",
       " '984',\n",
       " '853',\n",
       " '379',\n",
       " '426',\n",
       " '192',\n",
       " '689',\n",
       " '770',\n",
       " '817',\n",
       " '376',\n",
       " '90',\n",
       " '809',\n",
       " '208',\n",
       " '275',\n",
       " '497',\n",
       " '370',\n",
       " '971',\n",
       " '634',\n",
       " '900',\n",
       " '641',\n",
       " '653',\n",
       " '875',\n",
       " '628',\n",
       " '615',\n",
       " '507',\n",
       " '862',\n",
       " '617',\n",
       " '856',\n",
       " '988',\n",
       " '94',\n",
       " '659',\n",
       " '973',\n",
       " '542',\n",
       " '917',\n",
       " '87',\n",
       " '81',\n",
       " '399',\n",
       " '611',\n",
       " '833',\n",
       " '713',\n",
       " '180',\n",
       " '606',\n",
       " '704',\n",
       " '329',\n",
       " '281',\n",
       " '60',\n",
       " '32',\n",
       " '381',\n",
       " '651',\n",
       " '919',\n",
       " '779',\n",
       " '452',\n",
       " '293',\n",
       " '892',\n",
       " '647',\n",
       " '220',\n",
       " '327',\n",
       " '149',\n",
       " '429',\n",
       " '428',\n",
       " '512',\n",
       " '99',\n",
       " '530',\n",
       " '342',\n",
       " '576',\n",
       " '217',\n",
       " '529',\n",
       " '260',\n",
       " '86',\n",
       " '930',\n",
       " '959',\n",
       " '794',\n",
       " '948',\n",
       " '569',\n",
       " '268',\n",
       " '384',\n",
       " '404',\n",
       " '728',\n",
       " '718',\n",
       " '128',\n",
       " '336',\n",
       " '768',\n",
       " '740',\n",
       " '152',\n",
       " '365',\n",
       " '27',\n",
       " '618',\n",
       " '826',\n",
       " '218',\n",
       " '112',\n",
       " '151',\n",
       " '37',\n",
       " '315',\n",
       " '777',\n",
       " '904',\n",
       " '34',\n",
       " '953',\n",
       " '351',\n",
       " '444',\n",
       " '549',\n",
       " '555',\n",
       " '947',\n",
       " '263',\n",
       " '419',\n",
       " '135',\n",
       " '939',\n",
       " '565',\n",
       " '14',\n",
       " '580',\n",
       " '527',\n",
       " '10',\n",
       " '691',\n",
       " '474',\n",
       " '991',\n",
       " '378',\n",
       " '73',\n",
       " '3',\n",
       " '705',\n",
       " '101',\n",
       " '636',\n",
       " '210',\n",
       " '4',\n",
       " '837',\n",
       " '918',\n",
       " '259',\n",
       " '50',\n",
       " '276',\n",
       " '430',\n",
       " '595',\n",
       " '957',\n",
       " '506',\n",
       " '423',\n",
       " '343',\n",
       " '489',\n",
       " '767',\n",
       " '322',\n",
       " '339',\n",
       " '943']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testeventId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for e in eventId:\n",
    "    label.append(int(labels[e]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test = []\n",
    "for e in testeventId:\n",
    "    label_test.append(int(labels_test[e]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_test) # this is my ground truth label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(792,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.array(label)\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(792,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test = np.array(label)\n",
    "label_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.random.randn(T, batch_size, D)\n",
    "#Y = np.random.randint(1, size = 992)\n",
    "#X1 = np.random.rand(300, 20) # user y matrix\n",
    "#mask = np.random.randint(2, size=(300, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capture_Score(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.batch_size = batch_size\n",
    "        self.gstep = tf.Variable(0, dtype=tf.int32, trainable=False, name = 'global_step')\n",
    "        self.lr = 0.001\n",
    "        self.lstm_size = 50\n",
    "        self.training = False\n",
    "    def get_data(self):\n",
    "        with tf.name_scope('data'):\n",
    "            self.x = tf.placeholder(dtype=tf.float32, shape=[T, self.batch_size, D])\n",
    "            self.y = tf.placeholder(dtype= tf.int32, shape=[self.batch_size])\n",
    "        #with tf.name_scope('data_score'):\n",
    "            self.x1 = tf.placeholder(dtype=tf.float32, shape=[n_users, 50])\n",
    "            self.mask = tf.placeholder(dtype=tf.float32, shape=[n_users, self.batch_size])\n",
    "    \n",
    "    def inference(self):\n",
    "        with tf.variable_scope('Capture'):\n",
    "            Wa = tf.get_variable('Wa', shape=[D, D1], initializer=tf.random_normal_initializer)\n",
    "            ba = tf.get_variable('ba', shape= [D1], initializer=tf.random_normal_initializer)  \n",
    "            \n",
    "           # dropout_Wa = tf.nn.dropout(Wa, keep_prob=p) * p\n",
    "            dropout_Wa = tf.layers.dropout(inputs=Wa, rate=p, training=self.training)\n",
    "            x_reshape = tf.matmul(tf.reshape(self.x, [-1, D]), dropout_Wa) + ba\n",
    "            x1 = tf.reshape(x_reshape, [-1, self.batch_size, D1])\n",
    "            D1_new = x1.shape[-1]\n",
    "            weights = tf.get_variable('weights', shape = [D1_new, self.lstm_size],\n",
    "                                  initializer=tf.random_normal_initializer)\n",
    "            bias = tf.get_variable('bias', shape = [self.lstm_size], initializer=tf.random_normal_initializer)\n",
    "        \n",
    "            Wr = tf.get_variable('Wr', shape=[self.lstm_size, vj_size],initializer=tf.random_normal_initializer)\n",
    "            br = tf.get_variable('br', shape= [vj_size], initializer=tf.random_normal_initializer)   \n",
    "            \n",
    "            #dropout_Wr = tf.nn.dropout(Wr, keep_prob=p) * p  #changed here for dropout\n",
    "            dropout_Wr = tf.layers.dropout(inputs=Wr, rate=p, training=self.training)\n",
    "            _x1 = tf.transpose(x1, [1,0,2])\n",
    "            _x1 = tf.reshape(_x1, [-1, D1])\n",
    "\n",
    "            _x1 = tf.tanh(tf.matmul(_x1, weights) + bias)\n",
    "            _x1 = tf.split(_x1, T, 0)\n",
    "\n",
    "            lstm_cell = tf.contrib.rnn.BasicLSTMCell(self.lstm_size)\n",
    "\n",
    "            _, states = tf.contrib.rnn.static_rnn(lstm_cell, _x1, dtype=tf.float32)\n",
    "\n",
    "            lstm_last_state = states[-1]\n",
    "\n",
    "            vj = tf.matmul(lstm_last_state, dropout_Wr) + br\n",
    "            capture_vector_shape = vj.shape[-1]\n",
    "        \n",
    "        #for score\n",
    "        with tf.variable_scope('Score'):\n",
    "            Wu = tf.get_variable(name='Wu', shape=[50, Wu_size], initializer=tf.random_normal_initializer,\n",
    "                                regularizer = tf.contrib.layers.l2_regularizer(scale=reg))\n",
    "            bu = tf.get_variable('bu', shape= [Wu_size], initializer=tf.random_normal_initializer)\n",
    "\n",
    "            Ws = tf.get_variable('Ws', shape=[1,Wu_size], initializer = tf.random_normal_initializer)\n",
    "            bs = tf.get_variable('bs', shape=[1], initializer=tf.random_normal_initializer)\n",
    "        \n",
    "            y1 = tf.tanh(tf.matmul(self.x1, Wu) + bu)\n",
    "\n",
    "            s = tf.sigmoid(tf.reduce_sum(tf.multiply(y1,Ws), 1) + bs)\n",
    "\n",
    "            s = tf.multiply(s, tf.transpose(self.mask))\n",
    "\n",
    "            s= tf.reshape(s, shape = [self.batch_size, n_users])\n",
    "\n",
    "            s = tf.reduce_sum(s, 1)\n",
    "            s = tf.reshape(s, shape=[self.batch_size, 1])\n",
    "\n",
    "            score_vector_shape = s.shape[-1]\n",
    "        \n",
    "        #about to concatenate and pass through the final layer for score evaluation\n",
    "        s_vj = tf.concat(axis=1,values=[vj, s])\n",
    "        \n",
    "        with tf.variable_scope('FC7layer'):\n",
    "            Wt = tf.get_variable('Wt', shape=[capture_vector_shape+ score_vector_shape, 2], initializer=tf.random_normal_initializer)\n",
    "            bt = tf.get_variable('bt', shape = [2], initializer=tf.random_normal_initializer)\n",
    "        \n",
    "            self.logits = tf.matmul(s_vj, Wt) + bt\n",
    "\n",
    "    def loss(self):\n",
    "        #pass\n",
    "        #'''\n",
    "        with tf.name_scope('loss'):\n",
    "            entropy = tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=tf.one_hot(self.y, 2))\n",
    "            reg_loss = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "            #reg_loss = 0.5*reg*tf.nn.l2_loss((tf.trainable_variables()[8]))\n",
    "            self.loss = tf.reduce_mean(entropy, name='loss') +  0.5*tf.reduce_sum(reg_loss)\n",
    "        #'''\n",
    "    def optimizer(self):\n",
    "        #pass\n",
    "        with tf.name_scope('optimizer'):\n",
    "            self.optimizer = tf.train.AdamOptimizer(self.lr).minimize(self.loss, global_step = self.gstep)\n",
    "    \n",
    "    def evals(self):\n",
    "        #pass\n",
    "        #'''\n",
    "        with tf.name_scope('predicitons'):\n",
    "            preds = tf.nn.softmax(self.logits)\n",
    "            correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(tf.one_hot(self.y, 2), 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_preds, tf.float32))\n",
    "        #'''\n",
    "        \n",
    "    def summary(self):\n",
    "        #pass\n",
    "        #'''\n",
    "        with tf.name_scope('summary'):\n",
    "            tf.summary.scalar('loss', self.loss)\n",
    "            tf.summary.scalar('accuracy', self.accuracy)\n",
    "            tf.summary.histogram('losses', self.loss)\n",
    "            tf.summary.histogram('Wu', tf.trainable_variables()[8] )\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "        #'''\n",
    "    def build(self):\n",
    "        self.get_data()\n",
    "        self.inference()\n",
    "        self.loss()\n",
    "        self.optimizer()\n",
    "        self.evals()\n",
    "        self.summary()\n",
    "    \n",
    "    def train_once(self, sess, writer, epoch, step):\n",
    "        #pass\n",
    "        #'''\n",
    "        start_time = time.time()\n",
    "        self.training = True\n",
    "        total_loss = 0.0\n",
    "        iterations_perepoch = 792//batch_size\n",
    "        \n",
    "        for i in range(iterations_perepoch):\n",
    "\n",
    "            _, loss_, summary_ = sess.run([self.optimizer, self.loss, self.summary_op],\n",
    "                                          feed_dict={self.x:X[:,i*batch_size:i*batch_size+batch_size ,:], \n",
    "                                                     self.y:label[i*batch_size:i*batch_size+batch_size],\n",
    "                                                     self.x1: X1, \n",
    "                                                     self.mask: mask[:,i*batch_size:i*batch_size+batch_size]})\n",
    "            #print summary_\n",
    "            writer.add_summary(summary_, global_step=step)\n",
    "            total_loss += loss_\n",
    "\n",
    "        print('Loss at epoch{}: {} and took {} seconds'.format(epoch, total_loss/iterations_perepoch, time.time() - start_time))\n",
    "        l_initializer)  \n",
    "    #'''\n",
    "    def eval_once(self,sess, writer, epoch, step):\n",
    "        start_time = time.time()\n",
    "        self.training = True\n",
    "        total_acc = 0.0\n",
    "        iterations_perepoch = 199//batch_size\n",
    "        \n",
    "        for i in range(iterations_perepoch):\n",
    "\n",
    "            accuracy_, summary_= sess.run([self.accuracy, self.summary_op],\n",
    "                                          feed_dict={self.x:X_test[:,i*batch_size:i*batch_size+batch_size ,:], \n",
    "                                                     self.y:label_test[i*batch_size:i*batch_size+batch_size],\n",
    "                                                     self.x1: X1, \n",
    "                                                     self.mask: maskTest[:,i*batch_size:i*batch_size+batch_size]})\n",
    "            print accuracy_\n",
    "            writer.add_summary(summary_, global_step=step)\n",
    "            total_acc += accuracy_\n",
    "\n",
    "        print('Accuracy: {} and took {} seconds'.format(total_acc/iterations_perepoch, time.time() - start_time))\n",
    "    \n",
    "    def train(self, n_epochs):\n",
    "        #pass\n",
    "        #'''\n",
    "        writer = tf.summary.FileWriter('./graphs/capture_score', tf.get_default_graph())\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            step = self.gstep.eval()\n",
    "            \n",
    "            for epoch in range(n_epochs):\n",
    "                self.train_once(sess, writer, epoch, step)\n",
    "                self.eval_once(sess, writer, epoch, step)\n",
    "        writer.close()\n",
    "        #'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch0: 26.65126458904411 and took 4.4514319896698 seconds\n",
      "Accuracy: 0.521052638558965 and took 0.9195117950439453 seconds\n",
      "Loss at epoch1: 21.890521797952772 and took 4.31838321685791 seconds\n",
      "Accuracy: 0.5526315875743565 and took 0.8597469329833984 seconds\n",
      "Loss at epoch2: 18.704306831842736 and took 4.309796094894409 seconds\n",
      "Accuracy: 0.5421052677066702 and took 0.889373779296875 seconds\n",
      "Loss at epoch3: 15.840854499913469 and took 4.307809829711914 seconds\n",
      "Accuracy: 0.5315789541131571 and took 0.8881242275238037 seconds\n",
      "Loss at epoch4: 13.857473687280583 and took 4.331960439682007 seconds\n",
      "Accuracy: 0.515789478232986 and took 0.8961484432220459 seconds\n",
      "Loss at epoch5: 12.251555334163617 and took 4.301618576049805 seconds\n",
      "Accuracy: 0.5368421156155435 and took 0.8938302993774414 seconds\n",
      "Loss at epoch6: 11.191631425785113 and took 4.288168430328369 seconds\n",
      "Accuracy: 0.5368421171840868 and took 0.8787510395050049 seconds\n",
      "Loss at epoch7: 10.69962283025814 and took 4.316431045532227 seconds\n",
      "Accuracy: 0.557894744371113 and took 0.894967794418335 seconds\n",
      "Loss at epoch8: 10.291954330251187 and took 4.353509187698364 seconds\n",
      "Accuracy: 0.5368421156155435 and took 0.8986725807189941 seconds\n",
      "Loss at epoch9: 9.912289933313298 and took 4.359177589416504 seconds\n",
      "Accuracy: 0.5368421163998152 and took 0.892719030380249 seconds\n",
      "Loss at epoch10: 9.52554266965842 and took 4.385985851287842 seconds\n",
      "Accuracy: 0.5526315844372699 and took 0.8943562507629395 seconds\n",
      "Loss at epoch11: 9.21826961372472 and took 4.347175598144531 seconds\n",
      "Accuracy: 0.4947368510459599 and took 0.8937346935272217 seconds\n",
      "Loss at epoch12: 8.830654349508166 and took 4.3461384773254395 seconds\n",
      "Accuracy: 0.5105263206519579 and took 0.8918023109436035 seconds\n",
      "Loss at epoch13: 8.49102203755439 and took 4.382199764251709 seconds\n",
      "Accuracy: 0.48947369111211675 and took 0.9114780426025391 seconds\n",
      "Loss at epoch14: 8.153195634672914 and took 4.3153839111328125 seconds\n",
      "Accuracy: 0.47894736967588725 and took 0.8945510387420654 seconds\n",
      "Loss at epoch15: 7.843634092355076 and took 4.428505182266235 seconds\n",
      "Accuracy: 0.47894736967588725 and took 0.9142646789550781 seconds\n",
      "Loss at epoch16: 7.5361849145044255 and took 4.388870477676392 seconds\n",
      "Accuracy: 0.4736842128791307 and took 0.901116132736206 seconds\n",
      "Loss at epoch17: 7.245072521740878 and took 4.457061529159546 seconds\n",
      "Accuracy: 0.5263157933950424 and took 0.9052274227142334 seconds\n",
      "Loss at epoch18: 7.0518479407588135 and took 4.370374917984009 seconds\n",
      "Accuracy: 0.526315796532129 and took 0.9195253849029541 seconds\n",
      "Loss at epoch19: 6.889343611801727 and took 4.420544147491455 seconds\n",
      "Accuracy: 0.5157894813700726 and took 0.9078609943389893 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = Capture_Score()\n",
    "    model.build()\n",
    "    model.train(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d64c36cf63c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
