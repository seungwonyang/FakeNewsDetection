{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import re\n",
    "import string\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from gensim.models import doc2vec\n",
    "from collections import namedtuple\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient('localhost', 27017)\n",
    "db = client.csi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainEvents = np.load('./TrainTestValCreation/trainEvents.npy')\n",
    "testEvents = np.load('./TrainTestValCreation/testEvents.npy')\n",
    "valEvents = np.load('./TrainTestValCreation/valEvents.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building training set based on X_u (which was built using trainset userids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_userlist = np.load('./global_userlist.npy')\n",
    "global_userlist = list(global_userlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_u = np.load('./X_u/X_uSVD_trainset.npy')\n",
    "partitionperEvent = np.load('./partitionperEventStats.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numevents = len(trainEvents)\n",
    "totalpartitions = max(partitionperEvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = doc2vec.Doc2Vec.load('./doc2vecmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-11-04 18:33:35\n",
      "2015-11-06 05:32:20\n",
      "19\n",
      "72 True\n"
     ]
    }
   ],
   "source": [
    "partitions = 0\n",
    "actualevent = 0\n",
    "cnt = 0\n",
    "inputperEvent = np.zeros((numevents, totalpartitions, 122))\n",
    "#for e,l in trainEvents:\n",
    "for e in [72]:\n",
    "    tweetsperEvent = list(db.finalHydratedtweets.find({'myeventIndex': int(e)}).sort([(\"created_at\" , 1)]))\n",
    "    size = len(tweetsperEvent)\n",
    "    if (size != 0):\n",
    "        startTime =  (tweetsperEvent[0][\"created_at\"])\n",
    "        print (startTime)\n",
    "        stopTime =  (tweetsperEvent[size-1][\"created_at\"])\n",
    "        print (stopTime)\n",
    "        actualevent = actualevent + 1\n",
    "        engagement = []\n",
    "        partition = 0\n",
    "        x_U = []\n",
    "        k=0\n",
    "        time_interval = 0\n",
    "        time_intv = []\n",
    "        sTime = startTime\n",
    "        j = k\n",
    "        while (sTime <= stopTime):\n",
    "            #print (sTime)\n",
    "            engagements = 0\n",
    "            index = []\n",
    "            eTime = sTime + timedelta(hours=1)\n",
    "            #print ('k', j)\n",
    "            for ev in tweetsperEvent[j:]:\n",
    "                if (ev[\"created_at\"] < eTime and ev[\"created_at\"] >= sTime):\n",
    "                    engagements = engagements + 1\n",
    "                    ind = int(ev['user']['id_str'])\n",
    "                    \n",
    "                    index.append(X_u[global_userlist.index(ind)])\n",
    "                    j = j+1 \n",
    "                else:\n",
    "                    break\n",
    "            time_interval = time_interval + 1\n",
    "            if(engagements != 0):\n",
    "                partition = partition + 1\n",
    "                engagement.append(engagements)\n",
    "                x_U.append(np.mean(index, axis=0))\n",
    "                time_intv.append(time_interval)\n",
    "                time_interval = 0\n",
    "            sTime = eTime\n",
    "        print (partition)    \n",
    "        for l in range(partition):\n",
    "            inputperEvent[cnt, l, 0] = engagement[l]\n",
    "            inputperEvent[cnt, l, 1] = time_intv[l]\n",
    "            inputperEvent[cnt, l, 2:22] = x_U[l]\n",
    "            inputperEvent[cnt, l, 22:122] = model.docvecs[l+partitions]\n",
    "        partitions  = partitions + partition\n",
    "        cnt = cnt + 1\n",
    "        #evt = './FinalInputVectors/'+'e' + str(actualevent)\n",
    "        #np.save(evt, inputperEvent)                   \n",
    "    print (e, sum(engagement) == size)\n",
    "\n",
    "#np.save('./Dataset1/TrainCaptureDataset', inputperEvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "play = inputperEvent[0,:19,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 122)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        3.,  1.,  6.,  3.,  7.,  2.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating valset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "numevents = len(valEvents)\n",
    "totalpartitions = max(partitionperEvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763\n",
      "720\n",
      "942\n",
      "945\n",
      "82\n",
      "645\n",
      "470\n",
      "65\n",
      "427\n",
      "685\n",
      "587\n",
      "612\n",
      "737\n",
      "595\n",
      "50\n",
      "445\n",
      "179\n",
      "585\n",
      "314\n",
      "738\n",
      "700\n",
      "433\n",
      "297\n",
      "617\n",
      "241\n",
      "249\n",
      "62\n",
      "217\n",
      "934\n",
      "415\n",
      "593\n",
      "178\n",
      "611\n",
      "878\n",
      "666\n",
      "299\n",
      "770\n",
      "66\n",
      "51\n",
      "377\n",
      "691\n",
      "140\n",
      "526\n",
      "698\n",
      "530\n",
      "362\n",
      "73\n",
      "509\n",
      "750\n",
      "209\n",
      "653\n"
     ]
    }
   ],
   "source": [
    "partitions = 0\n",
    "actualevent = 0\n",
    "cnt = 0\n",
    "inputperEvent = np.zeros((numevents, totalpartitions, 122))\n",
    "for e,l in valEvents:\n",
    "#for e in [72]:\n",
    "    tweetsperEvent = list(db.finalHydratedtweets.find({'myeventIndex': int(e)}).sort([(\"created_at\" , 1)]))\n",
    "    size = len(tweetsperEvent)\n",
    "    if (size != 0):\n",
    "        startTime =  (tweetsperEvent[0][\"created_at\"])\n",
    "        stopTime =  (tweetsperEvent[size-1][\"created_at\"])\n",
    "        actualevent = actualevent + 1\n",
    "        engagement = []\n",
    "        partition = 0\n",
    "        x_U = []\n",
    "        k=0\n",
    "        time_interval = 0\n",
    "        time_intv = []\n",
    "        sTime = startTime\n",
    "        \n",
    "        while (sTime <= stopTime):\n",
    "            engagements = 0\n",
    "            index = []\n",
    "            eTime = sTime + timedelta(hours=1)\n",
    "            j = k\n",
    "            for ev in tweetsperEvent[j:]:\n",
    "                if (ev[\"created_at\"] < eTime and ev[\"created_at\"] >= sTime):\n",
    "                    engagements = engagements + 1\n",
    "                    ind = int(ev['user']['id_str'])\n",
    "                    if (ind in global_userlist):\n",
    "                        index.append(X_u[global_userlist.index(ind)])\n",
    "                    k = k+1 \n",
    "                else:\n",
    "                    break\n",
    "            time_interval = time_interval + 1\n",
    "            if(engagements != 0):\n",
    "                \n",
    "                partition = partition + 1\n",
    "                engagement.append(engagements)\n",
    "                if (len(index) == 0):\n",
    "                    x_U.append(np.array(20*[0]))\n",
    "                elif (len(index) ==1):\n",
    "                    x_U.append(np.array(index))\n",
    "                else:\n",
    "                    x_U.append(np.mean(index, axis=0))\n",
    "                time_intv.append(time_interval)\n",
    "                time_interval = 0\n",
    "            sTime = eTime\n",
    "           \n",
    "        for l in range(partition):\n",
    "            inputperEvent[cnt, l, 0] = engagement[l]\n",
    "            inputperEvent[cnt, l, 1] = time_intv[l]\n",
    "            inputperEvent[cnt, l, 2:22] = x_U[l]\n",
    "            tags = 'Event_'+str(e)+'_'+str(l+1)\n",
    "            inputperEvent[cnt, l, 22:122] = model.docvecs[tags]\n",
    "        #partitions  = partitions + partition\n",
    "        cnt = cnt + 1\n",
    "        #evt = './FinalInputVectors/'+'e' + str(actualevent)\n",
    "        #np.save(evt, inputperEvent)                   \n",
    "    print (e)\n",
    "    \n",
    "np.save('./Dataset1/ValCaptureDataset', inputperEvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  3.,  2.,  3.,  3.,  4.,  6.,  3.,  1.,  2.,  2.,  3.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputperEvent[0,:19,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116436.544592071"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(inputperEvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.73721098e-03,  -1.92332453e-03,  -3.76522775e-03,\n",
       "        -8.88505586e-04,  -1.68959319e-03,   1.00627407e-04,\n",
       "         1.79387087e-05,  -2.53060619e-03,  -1.00170662e-04,\n",
       "         8.93910815e-03,   1.20213154e-02,   8.40636115e-02,\n",
       "         8.25797938e-01,  -2.85368136e-03,   4.84504945e-03,\n",
       "        -3.12585400e-04,   1.88613851e-03,   1.28509394e-03,\n",
       "        -3.17723760e-05,  -5.02770134e-04])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_u[global_userlist.index(23863802)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "numevents = len(testEvents)\n",
    "totalpartitions = max(partitionperEvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840\n",
      "923\n",
      "776\n",
      "619\n",
      "854\n",
      "872\n",
      "833\n",
      "401\n",
      "842\n",
      "627\n",
      "492\n",
      "194\n",
      "251\n",
      "801\n",
      "310\n",
      "641\n",
      "96\n",
      "341\n",
      "924\n",
      "296\n",
      "571\n",
      "659\n",
      "901\n",
      "665\n",
      "946\n",
      "699\n",
      "538\n",
      "245\n",
      "518\n",
      "803\n",
      "759\n",
      "384\n",
      "964\n",
      "322\n",
      "765\n",
      "34\n",
      "247\n",
      "703\n",
      "126\n",
      "458\n",
      "95\n",
      "677\n",
      "970\n",
      "580\n",
      "618\n",
      "11\n",
      "351\n",
      "887\n",
      "227\n",
      "647\n",
      "881\n",
      "830\n",
      "654\n",
      "784\n",
      "643\n",
      "199\n",
      "813\n",
      "170\n",
      "949\n",
      "760\n",
      "333\n",
      "600\n",
      "826\n",
      "606\n",
      "642\n",
      "212\n",
      "123\n",
      "432\n",
      "968\n",
      "578\n",
      "857\n",
      "246\n",
      "319\n",
      "860\n",
      "673\n",
      "902\n",
      "809\n",
      "99\n",
      "302\n",
      "290\n",
      "407\n",
      "834\n",
      "442\n",
      "726\n",
      "431\n",
      "358\n",
      "486\n",
      "20\n",
      "793\n",
      "938\n",
      "675\n",
      "583\n",
      "695\n",
      "984\n",
      "190\n",
      "295\n",
      "722\n",
      "511\n",
      "678\n",
      "316\n",
      "214\n",
      "428\n",
      "330\n",
      "936\n",
      "757\n",
      "383\n",
      "83\n",
      "18\n",
      "307\n",
      "822\n",
      "958\n",
      "391\n",
      "493\n",
      "426\n",
      "762\n",
      "402\n",
      "485\n",
      "566\n",
      "110\n",
      "90\n",
      "620\n",
      "270\n",
      "915\n",
      "868\n",
      "629\n",
      "293\n",
      "91\n",
      "773\n",
      "244\n",
      "349\n",
      "575\n",
      "135\n",
      "885\n",
      "425\n",
      "321\n",
      "158\n",
      "273\n",
      "77\n",
      "188\n",
      "513\n",
      "287\n",
      "89\n",
      "907\n",
      "125\n",
      "100\n",
      "733\n",
      "570\n",
      "693\n"
     ]
    }
   ],
   "source": [
    "partitions = 0\n",
    "actualevent = 0\n",
    "cnt = 0\n",
    "inputperEvent = np.zeros((numevents, totalpartitions, 122))\n",
    "for e,l in testEvents:\n",
    "    tweetsperEvent = list(db.finalHydratedtweets.find({'myeventIndex': int(e)}).sort([(\"created_at\" , 1)]))\n",
    "    size = len(tweetsperEvent)\n",
    "    if (size != 0):\n",
    "        startTime =  (tweetsperEvent[0][\"created_at\"])\n",
    "        stopTime =  (tweetsperEvent[size-1][\"created_at\"])\n",
    "        actualevent = actualevent + 1\n",
    "        engagement = []\n",
    "        partition = 0\n",
    "        x_U = []\n",
    "        k=0\n",
    "        time_interval = 0\n",
    "        time_intv = []\n",
    "        sTime = startTime\n",
    "        \n",
    "        while (sTime <= stopTime):\n",
    "            engagements = 0\n",
    "            index = []\n",
    "            eTime = sTime + timedelta(hours=1)\n",
    "            j = k\n",
    "            for ev in tweetsperEvent[j:]:\n",
    "                if (ev[\"created_at\"] < eTime and ev[\"created_at\"] >= sTime):\n",
    "                    engagements = engagements + 1\n",
    "                    ind = int(ev['user']['id_str'])\n",
    "                    if (ind in global_userlist):\n",
    "                        index.append(X_u[global_userlist.index(ind)])\n",
    "                    k = k+1 \n",
    "                else:\n",
    "                    break\n",
    "            time_interval = time_interval + 1\n",
    "            if(engagements != 0):\n",
    "                \n",
    "                partition = partition + 1\n",
    "                engagement.append(engagements)\n",
    "                if (len(index) == 0):\n",
    "                    x_U.append(np.array(20*[0]))\n",
    "                elif (len(index) ==1):\n",
    "                    x_U.append(np.array(index))\n",
    "                else:\n",
    "                    x_U.append(np.mean(index, axis=0))\n",
    "                time_intv.append(time_interval)\n",
    "                time_interval = 0\n",
    "            sTime = eTime\n",
    "           \n",
    "        for l in range(partition):\n",
    "            inputperEvent[cnt, l, 0] = engagement[l]\n",
    "            inputperEvent[cnt, l, 1] = time_intv[l]\n",
    "            inputperEvent[cnt, l, 2:22] = x_U[l]\n",
    "            tags = 'Event_'+str(e)+'_'+str(l+1)\n",
    "            inputperEvent[cnt, l, 22:122] = model.docvecs[tags]\n",
    "        #partitions  = partitions + partition\n",
    "        cnt = cnt + 1\n",
    "        #evt = './FinalInputVectors/'+'e' + str(actualevent)\n",
    "        #np.save(evt, inputperEvent)                   \n",
    "    print (e)\n",
    "    \n",
    "np.save('./Dataset1/TestCaptureDataset', inputperEvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 9189, 122)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputperEvent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(inputperEvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
