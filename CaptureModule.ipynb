{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "T = 24\n",
    "D = 122\n",
    "D1 = 100\n",
    "vj_size = 20\n",
    "p = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('./Dataset1/TestCaptureDataset.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793, 9189, 122)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.abs(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Y.csv', Y, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7111991952"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "getsizeof(X)\n",
    "X.nbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793, 9189, 122)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:, :T, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793, 24, 122)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.reshape(b.shape[0],b.shape[1]*b.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793, 2928)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"./Train_X.csv\", b, fmt='%.5f', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df = pd.DataFrame(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2918</th>\n",
       "      <th>2919</th>\n",
       "      <th>2920</th>\n",
       "      <th>2921</th>\n",
       "      <th>2922</th>\n",
       "      <th>2923</th>\n",
       "      <th>2924</th>\n",
       "      <th>2925</th>\n",
       "      <th>2926</th>\n",
       "      <th>2927</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.036773</td>\n",
       "      <td>-0.071140</td>\n",
       "      <td>0.426733</td>\n",
       "      <td>-0.034005</td>\n",
       "      <td>-0.191315</td>\n",
       "      <td>-0.147640</td>\n",
       "      <td>1.151404</td>\n",
       "      <td>0.465436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127643</td>\n",
       "      <td>-0.113988</td>\n",
       "      <td>0.094525</td>\n",
       "      <td>-0.117658</td>\n",
       "      <td>0.070272</td>\n",
       "      <td>0.071117</td>\n",
       "      <td>-0.055388</td>\n",
       "      <td>-0.013856</td>\n",
       "      <td>0.024789</td>\n",
       "      <td>-0.097958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.074249</td>\n",
       "      <td>-0.163293</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>0.269994</td>\n",
       "      <td>-0.034141</td>\n",
       "      <td>0.024717</td>\n",
       "      <td>0.328111</td>\n",
       "      <td>0.100550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>-0.049510</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>-0.050053</td>\n",
       "      <td>0.034036</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>-0.112011</td>\n",
       "      <td>-0.040141</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.041521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087315</td>\n",
       "      <td>-0.001257</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>-0.023918</td>\n",
       "      <td>-0.005788</td>\n",
       "      <td>0.034570</td>\n",
       "      <td>-0.059576</td>\n",
       "      <td>-0.093437</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.045806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>-0.000751</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>-0.002253</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>-0.004340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2928 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1         2         3         4         5         6         7     \\\n",
       "0   1.0   1.0 -0.000210 -0.000172  0.000030 -0.000007 -0.000085 -0.000046   \n",
       "1   1.0   1.0  0.036773 -0.071140  0.426733 -0.034005 -0.191315 -0.147640   \n",
       "2   4.0   1.0 -0.074249 -0.163293  0.004470  0.269994 -0.034141  0.024717   \n",
       "3   1.0   1.0 -0.000044  0.000622 -0.000061 -0.000057 -0.000158  0.000274   \n",
       "4  10.0   1.0  0.003904 -0.000751  0.003049  0.000296  0.002879 -0.002253   \n",
       "\n",
       "       8         9       ...         2918      2919      2920      2921  \\\n",
       "0 -0.000076 -0.000140    ...     0.000000  0.000000  0.000000  0.000000   \n",
       "1  1.151404  0.465436    ...     0.127643 -0.113988  0.094525 -0.117658   \n",
       "2  0.328111  0.100550    ...     0.015274 -0.049510  0.003396 -0.050053   \n",
       "3 -0.000332  0.000073    ...     0.087315 -0.001257  0.005609 -0.023918   \n",
       "4  0.001559 -0.004340    ...     0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       2922      2923      2924      2925      2926      2927  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.070272  0.071117 -0.055388 -0.013856  0.024789 -0.097958  \n",
       "2  0.034036 -0.000433 -0.112011 -0.040141  0.001583  0.041521  \n",
       "3 -0.005788  0.034570 -0.059576 -0.093437  0.000633  0.045806  \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 2928 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Index(...) must be called with a collection of some kind, 'Y' was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-8a4dba98a0aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/tf3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                 mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n\u001b[0;32m--> 361\u001b[0;31m                                          copy=copy)\n\u001b[0m\u001b[1;32m    362\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_ndarray\u001b[0;34m(self, values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    522\u001b[0m                     \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_get_axes\u001b[0;34m(N, K, index, columns)\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m                 \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf3/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_ensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   4207\u001b[0m             \u001b[0mindex_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf3/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, fastpath, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m                          **kwargs)\n\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scalar_data_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             if (tupleize_cols and isinstance(data, list) and data and\n",
      "\u001b[0;32m~/.virtualenvs/tf3/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_scalar_data_error\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    708\u001b[0m         raise TypeError('{0}(...) must be called with a collection of some '\n\u001b[1;32m    709\u001b[0m                         'kind, {1} was passed'.format(cls.__name__,\n\u001b[0;32m--> 710\u001b[0;31m                                                       repr(data)))\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Index(...) must be called with a collection of some kind, 'Y' was passed"
     ]
    }
   ],
   "source": [
    "\n",
    "df2 = pd.DataFrame(Y, columns = 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  0\n",
       "3  1\n",
       "4  1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793, 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "y = pd.DataFrame()\n",
    "y = pd.DataFrame(Y)\n",
    "y.head()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793, 2928)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0\n",
       "2  1\n",
       "3  1\n",
       "4  1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1 = pd.concat([df, y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2919</th>\n",
       "      <th>2920</th>\n",
       "      <th>2921</th>\n",
       "      <th>2922</th>\n",
       "      <th>2923</th>\n",
       "      <th>2924</th>\n",
       "      <th>2925</th>\n",
       "      <th>2926</th>\n",
       "      <th>2927</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-8.454557e-05</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.036773</td>\n",
       "      <td>-0.071140</td>\n",
       "      <td>0.426733</td>\n",
       "      <td>-0.034005</td>\n",
       "      <td>-1.913154e-01</td>\n",
       "      <td>-0.147640</td>\n",
       "      <td>1.151404</td>\n",
       "      <td>0.465436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113988</td>\n",
       "      <td>0.094525</td>\n",
       "      <td>-0.117658</td>\n",
       "      <td>0.070272</td>\n",
       "      <td>0.071117</td>\n",
       "      <td>-0.055388</td>\n",
       "      <td>-0.013856</td>\n",
       "      <td>0.024789</td>\n",
       "      <td>-0.097958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.074249</td>\n",
       "      <td>-0.163293</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>0.269994</td>\n",
       "      <td>-3.414121e-02</td>\n",
       "      <td>0.024717</td>\n",
       "      <td>0.328111</td>\n",
       "      <td>0.100550</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049510</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>-0.050053</td>\n",
       "      <td>0.034036</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>-0.112011</td>\n",
       "      <td>-0.040141</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.041521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>-1.581225e-04</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001257</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>-0.023918</td>\n",
       "      <td>-0.005788</td>\n",
       "      <td>0.034570</td>\n",
       "      <td>-0.059576</td>\n",
       "      <td>-0.093437</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.045806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>-0.000751</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>2.879139e-03</td>\n",
       "      <td>-0.002253</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>-0.004340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.211429</td>\n",
       "      <td>-0.013712</td>\n",
       "      <td>-0.029309</td>\n",
       "      <td>-0.034764</td>\n",
       "      <td>9.557055e-02</td>\n",
       "      <td>0.219033</td>\n",
       "      <td>0.332743</td>\n",
       "      <td>0.239874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.342673</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>-0.242410</td>\n",
       "      <td>0.226634</td>\n",
       "      <td>0.041879</td>\n",
       "      <td>-0.466538</td>\n",
       "      <td>-0.287407</td>\n",
       "      <td>-0.161131</td>\n",
       "      <td>0.148916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-2.327674e-08</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>-3.059521e-04</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.019745</td>\n",
       "      <td>-0.016523</td>\n",
       "      <td>-0.044990</td>\n",
       "      <td>-0.015567</td>\n",
       "      <td>-8.799387e-03</td>\n",
       "      <td>-0.014599</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.189480</td>\n",
       "      <td>-0.001773</td>\n",
       "      <td>0.216858</td>\n",
       "      <td>-0.233626</td>\n",
       "      <td>-1.486670e-01</td>\n",
       "      <td>-0.245277</td>\n",
       "      <td>0.156750</td>\n",
       "      <td>-0.435859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025736</td>\n",
       "      <td>-0.272799</td>\n",
       "      <td>-0.089042</td>\n",
       "      <td>0.078240</td>\n",
       "      <td>-0.104261</td>\n",
       "      <td>0.143041</td>\n",
       "      <td>0.052181</td>\n",
       "      <td>-0.115057</td>\n",
       "      <td>0.061288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 2929 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1         2         3         4         5             6         7     \\\n",
       "0   1.0   1.0 -0.000210 -0.000172  0.000030 -0.000007 -8.454557e-05 -0.000046   \n",
       "1   1.0   1.0  0.036773 -0.071140  0.426733 -0.034005 -1.913154e-01 -0.147640   \n",
       "2   4.0   1.0 -0.074249 -0.163293  0.004470  0.269994 -3.414121e-02  0.024717   \n",
       "3   1.0   1.0 -0.000044  0.000622 -0.000061 -0.000057 -1.581225e-04  0.000274   \n",
       "4  10.0   1.0  0.003904 -0.000751  0.003049  0.000296  2.879139e-03 -0.002253   \n",
       "5   1.0   1.0 -1.211429 -0.013712 -0.029309 -0.034764  9.557055e-02  0.219033   \n",
       "6   2.0   1.0 -0.000035 -0.000009  0.000004  0.000013 -2.327674e-08 -0.000026   \n",
       "7   1.0   1.0  0.000099  0.000252  0.000013 -0.000334 -3.059521e-04 -0.000160   \n",
       "8  87.0   1.0  0.019745 -0.016523 -0.044990 -0.015567 -8.799387e-03 -0.014599   \n",
       "9   2.0   1.0 -1.189480 -0.001773  0.216858 -0.233626 -1.486670e-01 -0.245277   \n",
       "\n",
       "       8         9     ...       2919      2920      2921      2922      2923  \\\n",
       "0 -0.000076 -0.000140  ...   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  1.151404  0.465436  ...  -0.113988  0.094525 -0.117658  0.070272  0.071117   \n",
       "2  0.328111  0.100550  ...  -0.049510  0.003396 -0.050053  0.034036 -0.000433   \n",
       "3 -0.000332  0.000073  ...  -0.001257  0.005609 -0.023918 -0.005788  0.034570   \n",
       "4  0.001559 -0.004340  ...   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.332743  0.239874  ...  -0.342673  0.017242 -0.242410  0.226634  0.041879   \n",
       "6  0.000009 -0.000002  ...   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "7  0.000003 -0.000010  ...   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "8  0.001960  0.000503  ...   0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "9  0.156750 -0.435859  ...   0.025736 -0.272799 -0.089042  0.078240 -0.104261   \n",
       "\n",
       "       2924      2925      2926      2927  0     \n",
       "0  0.000000  0.000000  0.000000  0.000000     1  \n",
       "1 -0.055388 -0.013856  0.024789 -0.097958     0  \n",
       "2 -0.112011 -0.040141  0.001583  0.041521     1  \n",
       "3 -0.059576 -0.093437  0.000633  0.045806     1  \n",
       "4  0.000000  0.000000  0.000000  0.000000     1  \n",
       "5 -0.466538 -0.287407 -0.161131  0.148916     0  \n",
       "6  0.000000  0.000000  0.000000  0.000000     1  \n",
       "7  0.000000  0.000000  0.000000  0.000000     1  \n",
       "8  0.000000  0.000000  0.000000  0.000000     1  \n",
       "9  0.143041  0.052181 -0.115057  0.061288     1  \n",
       "\n",
       "[10 rows x 2929 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('./TainX1.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/tf3/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2521\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2522\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2523\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: -1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-06c8fe62852e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/tf3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf3/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf3/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3837\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3838\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3839\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3840\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf3/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2522\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2523\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2524\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: -1"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.load('./TrainTestValCreation/trainEvents.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= Y[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.load('./Dataset1/ValCaptureDataset.npy')\n",
    "Y_val = np.load('./TrainTestValCreation/valEvents.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('./Dataset1/TestCaptureDataset.npy')\n",
    "Y_test = np.load('./TrainTestValCreation/testEvents.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51, 9189, 122), (51, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape ,Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((148, 9189, 122), (148, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val[:, :T, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[:, :T, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51, 24, 122), (51, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape ,Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((148, 24, 122), (148, 2))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape ,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 793, 122)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.swapaxes(X, 0, 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 51, 122)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = np.swapaxes(X_val, 0, 1)\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 148, 122)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.swapaxes(X_test, 0, 1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val= Y_val[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = Y_test[:, 1]\n",
    "Y_test. shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24, 793, 122), (793,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = []\n",
    "for i in range(Y.shape[0]):\n",
    "    traindata.append((X[:, i, :], Y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "valdata = []\n",
    "for i in range(Y_val.shape[0]):\n",
    "    valdata.append((X_val[:, i, :], Y_val[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Caputure(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.batch_size = batch_size\n",
    "        self.gstep = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "        self.lr = 0.001\n",
    "        self.lstm_size = 50\n",
    "        self.training = False\n",
    "    def get_data(self):\n",
    "        self.x = tf.placeholder(dtype=tf.float32, shape=[T, self.batch_size, D])\n",
    "        self.y = tf.placeholder(dtype=tf.int32, shape=[self.batch_size])\n",
    "        \n",
    "    def inference(self):\n",
    "        \n",
    "        Wa = tf.get_variable('Wa', shape=[D, D1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        ba = tf.get_variable('ba', shape=[D1], initializer=tf.zeros_initializer)\n",
    "        dropout_Wa = tf.layers.dropout(inputs=Wa, rate=p, training=self.training)\n",
    "        x_reshape = tf.matmul(tf.reshape(self.x, [-1, D]), dropout_Wa) + ba\n",
    "        x1 = tf.reshape(x_reshape, [-1, self.batch_size, D1])\n",
    "        #x_reshape = tf.matmul(tf.reshape(self.x, [-1, D]), Wa) + ba\n",
    "        #x1 = tf.reshape(x_reshape, [-1, self.batch_size, D1])\n",
    "        \n",
    "        D1_new = x1.shape[-1]\n",
    "        weights = tf.get_variable('weights', shape=[D1_new, self.lstm_size], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        bias = tf.get_variable('bias', shape=[self.lstm_size], initializer=tf.zeros_initializer)\n",
    "        \n",
    "        Wr = tf.get_variable('Wr', shape=[self.lstm_size, vj_size], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        br = tf.get_variable('br', shape=[vj_size], initializer=tf.zeros_initializer)\n",
    "        \n",
    "        Wt = tf.get_variable('Wt', shape=[vj_size, 2], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        bt = tf.get_variable('bt', shape=[2], initializer=tf.zeros_initializer)\n",
    "        \n",
    "        _x1 = tf.transpose(x1, [1, 0, 2])\n",
    "        #print (_x1.shape)\n",
    "        #_x1 = tf.reshape(_x1, [-1, D1])\n",
    "        \n",
    "        #_x1 = tf.tanh(tf.matmul(_x1, weights) + bias)\n",
    "        #_x1 = tf.split(_x1, T, 0)\n",
    "        \n",
    "        #print (_x1.shape)\n",
    "        lstm_cell = tf.nn.rnn_cell.LSTMCell(self.lstm_size, state_is_tuple=True)\n",
    "        _, states = tf.nn.dynamic_rnn(lstm_cell, _x1, dtype=tf.float32)\n",
    "        \n",
    "        lstm_last_state = states[-1]\n",
    "        #states = tf.transpose(states, [1, 0, 2])\n",
    "        #lstm_last_state = tf.gather(states,tf.shape(states)[0] - 1)\n",
    "        #print (lstm_last_state.shape, Wr.shape)\n",
    "        vj = tf.matmul(lstm_last_state, Wr) + br\n",
    "\n",
    "        self.logits = tf.matmul(vj, Wt) + bt\n",
    "        \n",
    "    def loss(self):\n",
    "        entropy = tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels = tf.one_hot(self.y, 2))\n",
    "        self.loss = tf.reduce_mean(entropy, name = 'loss')\n",
    "        \n",
    "    def optimizer(self):\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.lr).minimize(self.loss, global_step = self.gstep)\n",
    "        \n",
    "    def evals(self):\n",
    "        preds = tf.nn.softmax(self.logits)\n",
    "        correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(tf.one_hot(self.y, 2), 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_preds, tf.float32))\n",
    "        \n",
    "    def summary(self):\n",
    "        tf.summary.scalar('loss', self.loss)\n",
    "        tf.summary.scalar('accuracy', self.accuracy)\n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "        \n",
    "    def build(self):\n",
    "        self.get_data()\n",
    "        self.inference()\n",
    "        self.loss()\n",
    "        self.optimizer()\n",
    "        self.evals()\n",
    "        self.summary()\n",
    "        \n",
    "    def train_once(self, sess, writer, epoch, step):\n",
    "        start_time = time.time()\n",
    "        self.training = True\n",
    "        total_loss = 0\n",
    "        iterations_perepoch = Y.shape[0]//batch_size\n",
    "        random.shuffle(traindata)\n",
    "        for i in range(len(traindata)):\n",
    "            X[:,i,:] = traindata[i][0]\n",
    "            Y[i]= traindata[i][1]\n",
    "        \n",
    "        \n",
    "        for i in range(iterations_perepoch):\n",
    "            _, loss_, summary_ = sess.run([self.optimizer, self.loss, self.summary_op], \n",
    "                                          feed_dict= {self.x: X[:, i*batch_size:i*batch_size+batch_size, :], \n",
    "                                                      self.y: Y[i*batch_size:i*batch_size+batch_size]})\n",
    "            writer.add_summary(summary_, global_step=step)\n",
    "            total_loss += loss_\n",
    "\n",
    "        print('Loss at epoch{}: {} and took {} seconds'.format(epoch, total_loss/iterations_perepoch, time.time() - start_time))\n",
    "          \n",
    "        \n",
    "    def eval_once(self,sess, writer, epoch, step):\n",
    "        start_time = time.time()\n",
    "        self.training = True\n",
    "        total_acc = 0.0\n",
    "        iterations_perepoch = Y_val.shape[0]//batch_size\n",
    "        \n",
    "        for i in range(iterations_perepoch):\n",
    "\n",
    "            accuracy_, summary_= sess.run([self.accuracy, self.summary_op],\n",
    "                                          feed_dict={self.x:X_val[:,i*batch_size:i*batch_size+batch_size ,:], \n",
    "                                                     self.y:Y_val[i*batch_size:i*batch_size+batch_size]})\n",
    "            #print (accuracy_)\n",
    "            writer.add_summary(summary_, global_step=step)\n",
    "            total_acc += accuracy_\n",
    "\n",
    "        print('Accuracy: {} and took {} seconds'.format(total_acc/iterations_perepoch, time.time() - start_time))\n",
    "        \n",
    "    def train(self, n_epochs):\n",
    "        writer = tf.summary.FileWriter('./graphs/capture_score', tf.get_default_graph())\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            step = self.gstep.eval()\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "                self.train_once(sess, writer, epoch, step)\n",
    "                self.eval_once(sess, writer, epoch, step)\n",
    "            \n",
    "            self.test(sess, writer, epoch, step)\n",
    "        writer.close()\n",
    "        \n",
    "    def test(self,sess, writer, epoch, step):\n",
    "        start_time = time.time()\n",
    "        total_acc = 0.0\n",
    "        iterations_perepoch = Y_test.shape[0]//batch_size\n",
    "        #print (iterations_perepoch, X_test.shape, Y_test.shape)\n",
    "        for i in range(iterations_perepoch):\n",
    "\n",
    "            accuracy_, summary_= sess.run([self.accuracy, self.summary_op],\n",
    "                                          feed_dict={self.x:X_test[:,i*batch_size:i*batch_size+batch_size ,:], \n",
    "                                                     self.y:Y_test[i*batch_size:i*batch_size+batch_size]})\n",
    "            #print (accuracy_)\n",
    "            writer.add_summary(summary_, global_step=step)\n",
    "            total_acc += accuracy_\n",
    "\n",
    "        print(' Test Accuracy: {} and took {} seconds'.format(total_acc/iterations_perepoch, time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch0: 0.7133443598844567 and took 0.8747537136077881 seconds\n",
      "Accuracy: 0.4791666666666667 and took 0.0312347412109375 seconds\n",
      "Loss at epoch1: 0.7003089371992617 and took 0.7297401428222656 seconds\n",
      "Accuracy: 0.4583333333333333 and took 0.015239477157592773 seconds\n",
      "Loss at epoch2: 0.6971292106472716 and took 0.7409307956695557 seconds\n",
      "Accuracy: 0.6875 and took 0.016907453536987305 seconds\n",
      "Loss at epoch3: 0.7021988314025256 and took 0.7379965782165527 seconds\n",
      "Accuracy: 0.3958333333333333 and took 0.015798091888427734 seconds\n",
      "Loss at epoch4: 0.6995674663660477 and took 0.7046303749084473 seconds\n",
      "Accuracy: 0.5 and took 0.01582169532775879 seconds\n",
      "Loss at epoch5: 0.6990004023727105 and took 0.7345685958862305 seconds\n",
      "Accuracy: 0.4583333333333333 and took 0.017247438430786133 seconds\n",
      "Loss at epoch6: 0.6927990548464716 and took 0.7188456058502197 seconds\n",
      "Accuracy: 0.5208333333333334 and took 0.014170169830322266 seconds\n",
      "Loss at epoch7: 0.7036525716586989 and took 0.7365758419036865 seconds\n",
      "Accuracy: 0.5 and took 0.01824808120727539 seconds\n",
      "Loss at epoch8: 0.6935630635339387 and took 0.7295749187469482 seconds\n",
      "Accuracy: 0.5 and took 0.01338052749633789 seconds\n",
      "Loss at epoch9: 0.6974284223147801 and took 0.6995971202850342 seconds\n",
      "Accuracy: 0.4583333333333333 and took 0.017874956130981445 seconds\n",
      "Loss at epoch10: 0.69574401573259 and took 0.6701908111572266 seconds\n",
      "Accuracy: 0.4166666666666667 and took 0.01677107810974121 seconds\n",
      "Loss at epoch11: 0.6975871482673957 and took 0.7272071838378906 seconds\n",
      "Accuracy: 0.4791666666666667 and took 0.01348423957824707 seconds\n",
      "Loss at epoch12: 0.694456681913259 and took 0.683319091796875 seconds\n",
      "Accuracy: 0.5833333333333334 and took 0.0145111083984375 seconds\n",
      "Loss at epoch13: 0.6980562343889353 and took 0.7159631252288818 seconds\n",
      "Accuracy: 0.5 and took 0.014638662338256836 seconds\n",
      "Loss at epoch14: 0.6938042993448219 and took 0.7222747802734375 seconds\n",
      "Accuracy: 0.4791666666666667 and took 0.013239622116088867 seconds\n",
      "Loss at epoch15: 0.6977329850196838 and took 0.7236263751983643 seconds\n",
      "Accuracy: 0.4375 and took 0.01690673828125 seconds\n",
      "Loss at epoch16: 0.6952471112718388 and took 0.6796653270721436 seconds\n",
      "Accuracy: 0.5208333333333334 and took 0.013812541961669922 seconds\n",
      "Loss at epoch17: 0.6959941387176514 and took 0.7276308536529541 seconds\n",
      "Accuracy: 0.5 and took 0.018224000930786133 seconds\n",
      "Loss at epoch18: 0.6940664612517065 and took 0.7508642673492432 seconds\n",
      "Accuracy: 0.5 and took 0.015758991241455078 seconds\n",
      "Loss at epoch19: 0.6917582665170942 and took 0.6960515975952148 seconds\n",
      "Accuracy: 0.4791666666666667 and took 0.015787839889526367 seconds\n",
      "Loss at epoch20: 0.6945479451393595 and took 0.7417781352996826 seconds\n",
      "Accuracy: 0.4791666666666667 and took 0.010387897491455078 seconds\n",
      "Loss at epoch21: 0.6935831393514361 and took 0.6822819709777832 seconds\n",
      "Accuracy: 0.5625 and took 0.01890873908996582 seconds\n",
      "Loss at epoch22: 0.6956306987879227 and took 0.7073478698730469 seconds\n",
      "Accuracy: 0.5 and took 0.014617681503295898 seconds\n",
      "Loss at epoch23: 0.6916047833403762 and took 0.7186434268951416 seconds\n",
      "Accuracy: 0.5 and took 0.016115188598632812 seconds\n",
      "Loss at epoch24: 0.6937902533278173 and took 0.7586319446563721 seconds\n",
      "Accuracy: 0.4583333333333333 and took 0.015719890594482422 seconds\n",
      "Loss at epoch25: 0.6954213052379842 and took 0.7120845317840576 seconds\n",
      "Accuracy: 0.4166666666666667 and took 0.012840747833251953 seconds\n",
      "Loss at epoch26: 0.6955438098128961 and took 0.7376928329467773 seconds\n",
      "Accuracy: 0.3541666666666667 and took 0.015658140182495117 seconds\n",
      "Loss at epoch27: 0.6943975905982815 and took 0.6851425170898438 seconds\n",
      "Accuracy: 0.3958333333333333 and took 0.011608600616455078 seconds\n",
      "Loss at epoch28: 0.696008563041687 and took 0.6969225406646729 seconds\n",
      "Accuracy: 0.4375 and took 0.018348217010498047 seconds\n",
      "Loss at epoch29: 0.6929819523071756 and took 0.7207152843475342 seconds\n",
      "Accuracy: 0.4375 and took 0.013756036758422852 seconds\n",
      "Loss at epoch30: 0.6943043129784721 and took 0.7462708950042725 seconds\n",
      "Accuracy: 0.4375 and took 0.01563239097595215 seconds\n",
      "Loss at epoch31: 0.6949811808916987 and took 0.7286832332611084 seconds\n",
      "Accuracy: 0.5 and took 0.017488479614257812 seconds\n",
      "Loss at epoch32: 0.6939118480195805 and took 0.6775169372558594 seconds\n",
      "Accuracy: 0.5 and took 0.019269466400146484 seconds\n",
      "Loss at epoch33: 0.6931831216325566 and took 0.732506275177002 seconds\n",
      "Accuracy: 0.3958333333333333 and took 0.015803098678588867 seconds\n",
      "Loss at epoch34: 0.6934891708043157 and took 0.6644046306610107 seconds\n",
      "Accuracy: 0.5 and took 0.019478559494018555 seconds\n",
      "Loss at epoch35: 0.6958123360361371 and took 0.6912751197814941 seconds\n",
      "Accuracy: 0.4166666666666667 and took 0.01988697052001953 seconds\n",
      "Loss at epoch36: 0.6958906845170625 and took 0.6860682964324951 seconds\n",
      "Accuracy: 0.5416666666666666 and took 0.01278233528137207 seconds\n",
      "Loss at epoch37: 0.6942327947032695 and took 0.7356112003326416 seconds\n",
      "Accuracy: 0.4791666666666667 and took 0.015081644058227539 seconds\n",
      "Loss at epoch38: 0.6923093661970022 and took 0.7285475730895996 seconds\n",
      "Accuracy: 0.5 and took 0.01599740982055664 seconds\n",
      "Loss at epoch39: 0.6932827063969204 and took 0.6779088973999023 seconds\n",
      "Accuracy: 0.4375 and took 0.012685537338256836 seconds\n",
      "Loss at epoch40: 0.6953469429697309 and took 0.7005243301391602 seconds\n",
      "Accuracy: 0.3958333333333333 and took 0.014541864395141602 seconds\n",
      "Loss at epoch41: 0.6939116594742756 and took 0.7127118110656738 seconds\n",
      "Accuracy: 0.5208333333333334 and took 0.018396615982055664 seconds\n",
      "Loss at epoch42: 0.6926916338959519 and took 0.7113897800445557 seconds\n",
      "Accuracy: 0.5208333333333334 and took 0.01720738410949707 seconds\n",
      "Loss at epoch43: 0.6933885934401531 and took 0.6819772720336914 seconds\n",
      "Accuracy: 0.5 and took 0.014436721801757812 seconds\n",
      "Loss at epoch44: 0.6934881502268265 and took 0.7040793895721436 seconds\n",
      "Accuracy: 0.4791666666666667 and took 0.015373706817626953 seconds\n",
      "Loss at epoch45: 0.6938902918173342 and took 0.7578468322753906 seconds\n",
      "Accuracy: 0.4583333333333333 and took 0.014698505401611328 seconds\n",
      "Loss at epoch46: 0.6941830199591967 and took 0.7095208168029785 seconds\n",
      "Accuracy: 0.4166666666666667 and took 0.016314983367919922 seconds\n",
      "Loss at epoch47: 0.6944141594731078 and took 0.6739871501922607 seconds\n",
      "Accuracy: 0.5 and took 0.01819467544555664 seconds\n",
      "Loss at epoch48: 0.693271166207839 and took 0.7045443058013916 seconds\n",
      "Accuracy: 0.5 and took 0.011365890502929688 seconds\n",
      "Loss at epoch49: 0.6941647286317787 and took 0.7074899673461914 seconds\n",
      "Accuracy: 0.5 and took 0.013443231582641602 seconds\n",
      "Loss at epoch50: 0.6933946159421182 and took 0.6860592365264893 seconds\n",
      "Accuracy: 0.5 and took 0.01746058464050293 seconds\n",
      "Loss at epoch51: 0.6928199371513055 and took 0.7175321578979492 seconds\n",
      "Accuracy: 0.5 and took 0.013197183609008789 seconds\n",
      "Loss at epoch52: 0.6935596964797195 and took 0.733403205871582 seconds\n",
      "Accuracy: 0.4791666666666667 and took 0.017261028289794922 seconds\n",
      "Loss at epoch53: 0.6950768840556242 and took 0.6901583671569824 seconds\n",
      "Accuracy: 0.3958333333333333 and took 0.015891551971435547 seconds\n",
      "Loss at epoch54: 0.6930754160394474 and took 0.7248721122741699 seconds\n",
      "Accuracy: 0.4583333333333333 and took 0.016516447067260742 seconds\n",
      "Loss at epoch55: 0.6934180892243678 and took 0.6889503002166748 seconds\n",
      "Accuracy: 0.4375 and took 0.016866683959960938 seconds\n",
      "Loss at epoch56: 0.6936757747007876 and took 0.7171175479888916 seconds\n",
      "Accuracy: 0.375 and took 0.016162395477294922 seconds\n",
      "Loss at epoch57: 0.6936643062805643 and took 0.7075543403625488 seconds\n",
      "Accuracy: 0.4583333333333333 and took 0.014893054962158203 seconds\n",
      "Loss at epoch58: 0.6929860406992386 and took 0.7146496772766113 seconds\n",
      "Accuracy: 0.4791666666666667 and took 0.014496564865112305 seconds\n",
      "Loss at epoch59: 0.6928002250437834 and took 0.7211904525756836 seconds\n",
      "Accuracy: 0.3958333333333333 and took 0.0171356201171875 seconds\n",
      "Loss at epoch60: 0.6928366872729087 and took 0.686445951461792 seconds\n",
      "Accuracy: 0.375 and took 0.013824939727783203 seconds\n",
      "Loss at epoch61: 0.6946475834262614 and took 0.7428951263427734 seconds\n",
      "Accuracy: 0.3958333333333333 and took 0.0169069766998291 seconds\n",
      "Loss at epoch62: 0.6948322191530344 and took 0.6895029544830322 seconds\n",
      "Accuracy: 0.3958333333333333 and took 0.021416902542114258 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch63: 0.6937443845126093 and took 0.7192628383636475 seconds\n",
      "Accuracy: 0.3958333333333333 and took 0.01645040512084961 seconds\n",
      "Loss at epoch64: 0.6938455919830167 and took 0.7317066192626953 seconds\n",
      "Accuracy: 0.375 and took 0.013247489929199219 seconds\n",
      "Loss at epoch65: 0.6940046256902267 and took 0.7413606643676758 seconds\n",
      "Accuracy: 0.625 and took 0.01555490493774414 seconds\n",
      "Loss at epoch66: 0.6938734382999187 and took 0.7196574211120605 seconds\n",
      "Accuracy: 0.5416666666666666 and took 0.018010616302490234 seconds\n",
      "Loss at epoch67: 0.6933457583797221 and took 0.687755823135376 seconds\n",
      "Accuracy: 0.5833333333333334 and took 0.014233112335205078 seconds\n",
      "Loss at epoch68: 0.6940212590353829 and took 0.6940624713897705 seconds\n",
      "Accuracy: 0.6041666666666666 and took 0.015471696853637695 seconds\n",
      "Loss at epoch69: 0.6936388745599863 and took 0.729602575302124 seconds\n",
      "Accuracy: 0.5 and took 0.014215230941772461 seconds\n",
      " Test Accuracy: 0.5 and took 0.05000424385070801 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = Caputure()\n",
    "    model.build()\n",
    "    model.train(n_epochs=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
